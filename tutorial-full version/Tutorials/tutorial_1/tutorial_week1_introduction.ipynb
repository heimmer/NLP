{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heimmer/NLP/blob/main/tutorial-full%20version/Tutorials/tutorial_1/tutorial_week1_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spRGRRPVdaUc"
      },
      "source": [
        "# CS6493 - Tutorial 1\n",
        "## Introduction to JupyterHub and PyTorch\n",
        "\n",
        "Welcome to CS6493 tutorial. In this tutorial, you will get familiar with our exprimental environment, and also practice with some basic PyTorch operations.\n",
        "\n",
        "## 1. JupyterHub\n",
        "\n",
        "You can use the JupyterHub to run the toy models. Here are some notes for JupyterHub:\n",
        "\n",
        "- You are supposed to be familiar with Python and Jupyter;\n",
        "- Enter https://mljh.cs.cityu.edu.hk/ and login with your **EID** to use JupyterHub;\n",
        "- Each student will be allocated with **8GB GPU memories**;\n",
        "- Accommodate up to **60 students** to simultaneously use the JpuyterHub;\n",
        "- **DO NOT** attempt to load large models, such as T5 and GPT-3 on JupyterHub;\n",
        "- **DO NOT** run a program more than 1 week.\n",
        "\n",
        "## 2. PyTorch\n",
        "\n",
        "We use [PyTorch](https://pytorch.org/) framework to finish the implementations. In this section, we will introduce the installation, the basic operations of PyTorch.\n",
        "\n",
        "### 2.1 Installation\n",
        "Here, we install PyTorch with GPU supports. So, we first need to know the CUDA version in the server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS4Kq-OPdaUe",
        "outputId": "7dc71e9f-3aee-405b-ca15-238c5913bbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 25 08:09:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJm8SuKcdaUf"
      },
      "source": [
        "Then, we find the suitable version package from https://pytorch.org/. Past the command and run in the cell.\n",
        "\n",
        "Here we choose the version 1.10.1 with CUDA 10.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t83G5QidaUf",
        "outputId": "1f7f949b-2659-4461-de6e-3aa0b46b811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMyB5kaXdaUf"
      },
      "source": [
        "Now we can check the version of our installed package and whether it supports to GPUs,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq8A8b-3daUg",
        "outputId": "5af2f377-416c-4fba-a1f0-df1b998e268b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  2.0.0+cu118\n",
            "GPU support:  True\n",
            "Available devices count:  1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"PyTorch version: \", torch.__version__)\n",
        "print(\"GPU support: \", torch.cuda.is_available())\n",
        "print(\"Available devices count: \", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NiXNPNYdaUg"
      },
      "source": [
        "## 2.2 Quick start - Tensor in PyTorch\n",
        "\n",
        "In this section, we introcue some basic concepts and operations of Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nCbgYxw3daUg"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIuvnlkxdaUg"
      },
      "source": [
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators.\n",
        "\n",
        "### Create Tensors\n",
        "\n",
        "Tensors can be created directly from data or NumPy arrays. You can assign the data type to the tensor. Otherwise, the data type would be automatically inferred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kksDw3csdaUg",
        "outputId": "04a43baf-ad74-418b-eb5f-bd47169ff4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Tensor: \n",
            " tensor([[0, 1],\n",
            "        [2, 3]]) \n",
            "\n",
            "Float Tensor: \n",
            " tensor([[0., 1.],\n",
            "        [2., 3.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [[0,1], [2,3]]\n",
        "tensor_data = torch.tensor(data)\n",
        "tensor_data_float = torch.tensor(data).float()\n",
        "print(f\"Long Tensor: \\n {tensor_data} \\n\")  # the data type is LongTensor\n",
        "print(f\"Float Tensor: \\n {tensor_data_float} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ_9ycDtdaUh",
        "outputId": "1c7938ef-9a2f-450a-e553-471f67e27fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Tensor: \n",
            " tensor([[0, 1],\n",
            "        [2, 3]]) \n",
            "\n",
            "Float Tensor: \n",
            " tensor([[0., 1.],\n",
            "        [2., 3.]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "np_data = np.array(data)\n",
        "tensor_np_data = torch.tensor(np_data)\n",
        "tensor_np_data_float = torch.tensor(np_data).float()\n",
        "print(f\"Long Tensor: \\n {tensor_np_data} \\n\")  # the data type is LongTensor\n",
        "print(f\"Float Tensor: \\n {tensor_np_data_float} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeNe06u-daUh"
      },
      "source": [
        "You can also create the tensors filled with constant (e.g., 0 and 1) or random values,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJN_5f6sdaUh",
        "outputId": "d23e4e31-9db2-4eb0-e6ad-da021c89a63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7450, 0.1870, 0.7166],\n",
            "        [0.6036, 0.4082, 0.9448]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "zeros_tensor = torch.zeros((2,3))\n",
        "ones_tensor = torch.ones((2,3))\n",
        "random_tensor = torch.rand((2,3))\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Random Tensor: \\n {random_tensor} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7iygsPvdaUh"
      },
      "source": [
        "### Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu20PJkldaUh",
        "outputId": "0f06f392-1969-4545-9fce-8dfbf6185b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([2, 3])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(2,3)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4CE_32daUh"
      },
      "source": [
        "### Operations on Tensors\n",
        "\n",
        "There are over 100 tensor operations, including arthmetic, linear algebra, matrix manipulation and more. In this section, we only introduce some frequently used operations in our later tutorials and projects.\n",
        "\n",
        "**Move Tensor to Device**\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to()` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF-7oGbNdaUh",
        "outputId": "6e407d19-fec0-4901-abb2-1838dd1c15cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# move tensor to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZIuE0vrdaUi"
      },
      "source": [
        "**Tensor indexing, slicing and reshape**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL7r6QjxdaUi",
        "outputId": "735da386-2e19-44c0-efc4-48343d0c0d99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3975, 0.0207, 0.3443, 0.3125, 0.4004, 0.7201],\n",
              "        [0.6078, 0.8387, 0.5852, 0.0792, 0.2421, 0.3974],\n",
              "        [0.9580, 0.8436, 0.4111, 0.6594, 0.4107, 0.7563],\n",
              "        [0.4197, 0.8792, 0.0617, 0.5252, 0.8393, 0.4848]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tensor = torch.rand(4, 6)\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBDLZExpdaUi",
        "outputId": "ec60791d-2088-4da9-8f87-d3060b6f6743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([0.3975, 0.0207, 0.3443, 0.3125, 0.4004, 0.7201])\n",
            "First column: tensor([0.3975, 0.6078, 0.9580, 0.4197])\n",
            "Last column: tensor([0.7201, 0.3974, 0.7563, 0.4848])\n"
          ]
        }
      ],
      "source": [
        "# let take a look at its first row and column\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:,0]}\")\n",
        "print(f\"Last column: {tensor[:, -1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRnDou_pdaUi",
        "outputId": "c1786f74-62b1-45f7-f5f0-e9ab6e4ad5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshape to (2,12): \n",
            " tensor([[0.3975, 0.0207, 0.3443, 0.3125, 0.4004, 0.7201, 0.6078, 0.8387, 0.5852,\n",
            "         0.0792, 0.2421, 0.3974],\n",
            "        [0.9580, 0.8436, 0.4111, 0.6594, 0.4107, 0.7563, 0.4197, 0.8792, 0.0617,\n",
            "         0.5252, 0.8393, 0.4848]]) \n",
            "\n",
            "Reshape to (2,2,6): \n",
            " tensor([[[0.3975, 0.0207, 0.3443, 0.3125, 0.4004, 0.7201],\n",
            "         [0.6078, 0.8387, 0.5852, 0.0792, 0.2421, 0.3974]],\n",
            "\n",
            "        [[0.9580, 0.8436, 0.4111, 0.6594, 0.4107, 0.7563],\n",
            "         [0.4197, 0.8792, 0.0617, 0.5252, 0.8393, 0.4848]]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# reshape\n",
        "print(f\"Reshape to (2,12): \\n {tensor.view(2, 12)} \\n\")\n",
        "print(f\"Reshape to (2,2,6): \\n {tensor.view(-1, 2, 6)} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piykY81ldaUi"
      },
      "source": [
        "**Joining tensors.** You can use torch.cat to concatenate a sequence of tensors along a given dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thMGf8n4daUi",
        "outputId": "fd3cc71e-4fa8-44e1-9c63-cd94c002fe7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3975, 0.0207, 0.3443, 0.3125, 0.4004, 0.7201, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.6078, 0.8387, 0.5852, 0.0792, 0.2421, 0.3974, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.9580, 0.8436, 0.4111, 0.6594, 0.4107, 0.7563, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.4197, 0.8792, 0.0617, 0.5252, 0.8393, 0.4848, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "t1 = torch.zeros(4, 2)\n",
        "new_t = torch.cat([tensor, t1, t1], dim=1)\n",
        "new_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8toYg8OdaUi"
      },
      "source": [
        "**Arithmetic operations**\n",
        "\n",
        "The basic arithmetic operations of Pytorch are similar with those in Numpy, such as `.pow()`, `.div()`, `.sum()` and more. Here we talk more about multiplication in Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WNs7F5_daUj",
        "outputId": "00fa44cc-13e9-42a3-f7c3-10ed6acb8b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of original tensor: torch.Size([4, 6])\n",
            "Shape of matrix multiplication resulting tensor: torch.Size([4, 4])\n",
            "Shape of element-wise product resulting tensor: torch.Size([4, 6])\n"
          ]
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2 will have the same value\n",
        "print(f\"Shape of original tensor: {tensor.shape}\")\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "print(f\"Shape of matrix multiplication resulting tensor: {y1.shape}\")\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "print(f\"Shape of element-wise product resulting tensor: {z1.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJo3-7UPdaUj"
      },
      "source": [
        "## 2.3 Practice\n",
        "\n",
        "In NLP, we have a very popular and famous techique, termed **Attention** which is used to measure the improtance among each components. Formally, we define the attention mechanism as:\n",
        "\n",
        "$Attention(\\mathbf{Q},\\mathbf{K},\\mathbf{V}) = \\text{Softmax}(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}})\\mathbf{V}$\n",
        "\n",
        "$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$,\n",
        "\n",
        "you can attempt to implement softmax function and attention by yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QO-ZRXkRdaUj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "v= torch.rand((2,4,8))\n",
        "k = v\n",
        "q = torch.rand((2,4,8))\n",
        "d_k = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qNZoC4cedaUj"
      },
      "outputs": [],
      "source": [
        "# insert your code\n",
        "def softmax(x, dim=0):\n",
        "  # s = x.clone().detach()\n",
        "  # denominator = torch.sum(torch.exp(x))\n",
        "  # for i in x:\n",
        "  #   s[i] = torch.exp(x[i])/denominator\n",
        "  x_exp = x.exp()\n",
        "  partition = x_exp.sum(dim=dim, keepdim=True)\n",
        "  return x_exp/partition\n",
        "\n",
        "def attention(q, k, v):\n",
        "  # return softmax((q@k.T)/torch.sqrt(d_k)) @ v\n",
        "  return torch.bmm(softmax(torch.bmm(q,k.transpose(2,1))/math.sqrt(d_k),dim=1),v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention(q,k,v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaUI3fxUhj-V",
        "outputId": "9510333a-6b0f-42a5-e9b8-1e3998f56dfc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3062, 0.5595, 0.5241, 0.4910, 0.3022, 0.6360, 0.3312, 0.5216],\n",
              "         [0.4192, 0.7582, 0.6774, 0.6444, 0.3777, 0.8300, 0.4416, 0.6756],\n",
              "         [0.4569, 0.8445, 0.7502, 0.7205, 0.4239, 0.9129, 0.4603, 0.7712],\n",
              "         [0.3435, 0.6333, 0.5775, 0.5476, 0.3299, 0.7010, 0.3552, 0.5877]],\n",
              "\n",
              "        [[0.5498, 0.3704, 0.4734, 0.3011, 0.3211, 0.2853, 0.6813, 0.2172],\n",
              "         [0.7086, 0.4699, 0.5952, 0.3611, 0.4021, 0.3706, 0.8162, 0.2893],\n",
              "         [0.5982, 0.4007, 0.4965, 0.3083, 0.3414, 0.3131, 0.6943, 0.2414],\n",
              "         [0.6934, 0.4863, 0.5570, 0.3725, 0.3759, 0.3805, 0.8019, 0.2751]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlrZY5dzdaUj"
      },
      "source": [
        "**Think more** how wo implement self-attention if you only have access to a hidden state **H**. (Mapping **H** with a learnable matrix **W** to **Q, K, V**)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKG8LXT5hiu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCtBue51daUj"
      },
      "outputs": [],
      "source": [
        "# insert your code"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cb37b736de3441abeb40a16b7776021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d7c411037b64376982661ff15aa487b",
              "IPY_MODEL_b1f26ed3384b4cfd95f61bc7626f9aff",
              "IPY_MODEL_24025f5f822e4bd2805cd530da066dee"
            ],
            "layout": "IPY_MODEL_e40ef8ee43594c6ba2289fe5a2f6c35f"
          }
        },
        "6d7c411037b64376982661ff15aa487b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c625e5deab5467d99f831e71115d03e",
            "placeholder": "​",
            "style": "IPY_MODEL_95243484c30c4f00bbbca16aeb2fd358",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b1f26ed3384b4cfd95f61bc7626f9aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdfb9b142c24456a937d6c6a6549519",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50b696fad9ca41639c373a56dbe89420",
            "value": 26
          }
        },
        "24025f5f822e4bd2805cd530da066dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57582f68d3da440193c5231507aa5396",
            "placeholder": "​",
            "style": "IPY_MODEL_f1b95b25bb904364abdbbab5946b81d1",
            "value": " 26.0/26.0 [00:00&lt;00:00, 978B/s]"
          }
        },
        "e40ef8ee43594c6ba2289fe5a2f6c35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c625e5deab5467d99f831e71115d03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95243484c30c4f00bbbca16aeb2fd358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdfb9b142c24456a937d6c6a6549519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b696fad9ca41639c373a56dbe89420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57582f68d3da440193c5231507aa5396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b95b25bb904364abdbbab5946b81d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c79c82bccb85415ea8c90b86562ba663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cfd8ecf5ca741c8be36e3991769df7c",
              "IPY_MODEL_b93ce7212179474bac487049babd6091",
              "IPY_MODEL_c4de165618ff474b98e7807267bb3f10"
            ],
            "layout": "IPY_MODEL_169f478857a34225b1db7098d1853326"
          }
        },
        "9cfd8ecf5ca741c8be36e3991769df7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc2f1d145b14e008e2412b7c2270c6c",
            "placeholder": "​",
            "style": "IPY_MODEL_03962a97d3e64bf9af87a2178ebf4e73",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b93ce7212179474bac487049babd6091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac87dfd2bb534a3c971b77360ac720ad",
            "max": 641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cb7b0940b8048409f906e2fcc45d07b",
            "value": 641
          }
        },
        "c4de165618ff474b98e7807267bb3f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f047765f4447478a96645ddef19ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_1d38c01aaf2d4f119be8bbe6406a5395",
            "value": " 641/641 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "169f478857a34225b1db7098d1853326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc2f1d145b14e008e2412b7c2270c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03962a97d3e64bf9af87a2178ebf4e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac87dfd2bb534a3c971b77360ac720ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb7b0940b8048409f906e2fcc45d07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f047765f4447478a96645ddef19ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d38c01aaf2d4f119be8bbe6406a5395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb47052903c64f3c8f3761b23ebe5685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7b7c7d62cfc4b609dbb3b364ab96187",
              "IPY_MODEL_66dfb24424164c38b9ea9239c4c2dc40",
              "IPY_MODEL_977924568223464ba8319deb85649633"
            ],
            "layout": "IPY_MODEL_9132b14861004a11bb768d45ea490d45"
          }
        },
        "e7b7c7d62cfc4b609dbb3b364ab96187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2610f8d9a943bd9e1e68111ae0d869",
            "placeholder": "​",
            "style": "IPY_MODEL_6f0dd7a145d34376add89df435cbdb1e",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "66dfb24424164c38b9ea9239c4c2dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a302de47b24ca98aa4427d7f9ab940",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaa9eb2f876649df94df950b64697bda",
            "value": 1042301
          }
        },
        "977924568223464ba8319deb85649633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885fb41b92ca436aa6666dfe18ff92a0",
            "placeholder": "​",
            "style": "IPY_MODEL_bda28c44f55b431ead843b1b249c363f",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 6.86MB/s]"
          }
        },
        "9132b14861004a11bb768d45ea490d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2610f8d9a943bd9e1e68111ae0d869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0dd7a145d34376add89df435cbdb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a302de47b24ca98aa4427d7f9ab940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa9eb2f876649df94df950b64697bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "885fb41b92ca436aa6666dfe18ff92a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda28c44f55b431ead843b1b249c363f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa20a48c6d724619bc1e960d0ebec5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_414a240375984693b83dd2f4f6125d01",
              "IPY_MODEL_ed6231c81fa94be7988c5f7f41a2c8da",
              "IPY_MODEL_8df2989bec5040488ad94d4a992e28fc"
            ],
            "layout": "IPY_MODEL_3790f0538f694c638df1c5d548529124"
          }
        },
        "414a240375984693b83dd2f4f6125d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e90ae173b6240a6919ff13461325aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_1366157f3dc44a47b58df8fb34bf7895",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "ed6231c81fa94be7988c5f7f41a2c8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c7a210fb844579aa605942d00ab4f3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7e0228d542d4087966470e6e5752d4a",
            "value": 456318
          }
        },
        "8df2989bec5040488ad94d4a992e28fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d34430db16423b875734570ea10408",
            "placeholder": "​",
            "style": "IPY_MODEL_c03b40558da3415cb6c55889efca0e35",
            "value": " 456k/456k [00:00&lt;00:00, 4.01MB/s]"
          }
        },
        "3790f0538f694c638df1c5d548529124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e90ae173b6240a6919ff13461325aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1366157f3dc44a47b58df8fb34bf7895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8c7a210fb844579aa605942d00ab4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e0228d542d4087966470e6e5752d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04d34430db16423b875734570ea10408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03b40558da3415cb6c55889efca0e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7945faae5ea473a90041b3c0c814ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0669ef280ea4566b66bdcd5e73cc351",
              "IPY_MODEL_59391bde7407468b961b221ee8e91e21",
              "IPY_MODEL_65dd4fc5a31341118219da523987ddaa"
            ],
            "layout": "IPY_MODEL_91aa32f87f0642bca448425f265db362"
          }
        },
        "f0669ef280ea4566b66bdcd5e73cc351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690287478227420ca8dbc72a984145d2",
            "placeholder": "​",
            "style": "IPY_MODEL_48c5232cb7264e4fa3239b00f288dbe3",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "59391bde7407468b961b221ee8e91e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045522048ffc4c7ebabc0a699c4489f0",
            "max": 351265583,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a4d35a836b24e05aa85b81faa4eec1e",
            "value": 351265583
          }
        },
        "65dd4fc5a31341118219da523987ddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5054d181fb3c4cfa80e36c2db6f648d8",
            "placeholder": "​",
            "style": "IPY_MODEL_dac550f8975841aba051d4a121252dcf",
            "value": " 351M/351M [00:04&lt;00:00, 77.0MB/s]"
          }
        },
        "91aa32f87f0642bca448425f265db362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690287478227420ca8dbc72a984145d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c5232cb7264e4fa3239b00f288dbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "045522048ffc4c7ebabc0a699c4489f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a4d35a836b24e05aa85b81faa4eec1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5054d181fb3c4cfa80e36c2db6f648d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac550f8975841aba051d4a121252dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e91ad9eb7854d1e9d72ab588c434265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2628cb319c794cefa5e5d09c969e9b17",
              "IPY_MODEL_405f8a185c83430f9388d0e164c18f94",
              "IPY_MODEL_5d4cd67ffb5d4617861704da9c9d5f7a"
            ],
            "layout": "IPY_MODEL_cdbf1124dada4141b10cc8870b6bd6df"
          }
        },
        "2628cb319c794cefa5e5d09c969e9b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766f9020eb8f46659794511d676ddddf",
            "placeholder": "​",
            "style": "IPY_MODEL_4969da3253d24c179d0dd789bef571e4",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "405f8a185c83430f9388d0e164c18f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9471acceec1c4b8a80ee8ec29edba781",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf364d97ca0a4933b277ace0cd4c3e37",
            "value": 124
          }
        },
        "5d4cd67ffb5d4617861704da9c9d5f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c6546ad07946469034ba8590e682b4",
            "placeholder": "​",
            "style": "IPY_MODEL_2759f1a6be5444f9a7ff1b2f9f47fc84",
            "value": " 124/124 [00:00&lt;00:00, 1.65kB/s]"
          }
        },
        "cdbf1124dada4141b10cc8870b6bd6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766f9020eb8f46659794511d676ddddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4969da3253d24c179d0dd789bef571e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9471acceec1c4b8a80ee8ec29edba781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf364d97ca0a4933b277ace0cd4c3e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6c6546ad07946469034ba8590e682b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2759f1a6be5444f9a7ff1b2f9f47fc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heimmer/NLP/blob/main/GPTRick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrNfVNueNhR"
      },
      "source": [
        "#Make your own Rick Sanchez (bot) with Transformers and DialoGPT fine-tuning\n",
        "\n",
        "by [Rostyslav Neskorozhenyi](https://www.linkedin.com/in/slanj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78afhsngLZMw"
      },
      "source": [
        "I am a big fan of 'Rick and Morty' and NLP (Natural Language Processing). After watching the last episode of a mad scientist's and his grandson's adventures I realized that it's not a coincidence and I have to apply my knowledge in NLP and Machine Learning to create my own Rick (in a form of chat-bot, at least for now).\n",
        "\n",
        "![alt text](https://media.giphy.com/media/ZdBnIqBeVWBYTobH8U/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "The path to creating virtual Rick was not easy. I tried many models and approaches but virtual Rick did not want to find a common language with me for a long time. Rick's first response to my greeting was \"I am not your buddy\" (to tell you the truth, in the beginning he knew only this phrase). But I did not give up and with the help of excellent Transformers library and Microsoft's Large-scale Pretrained Response Generation Model (DialoGPT) I managed to talk heart-to-heart with Rick. Here is one of our conversations:\n",
        "\n",
        "**User**:Hey, Rick, make me a time machine <br>\n",
        "**RickBot**: You're a monster! <br>\n",
        "**User**:No, I just want to travel in time <br>\n",
        "**RickBot**: To the past. <br>\n",
        "**User**:yes <br>\n",
        "**RickBot**: No time machine, please. <br>\n",
        "**User**:But I need it <br>\n",
        "**RickBot**: You don't need it, Morty. Just do it. <br>\n",
        "**User**:I want to see antient Greece <br>\n",
        "**RickBot**: Oh, geez. <br>\n",
        "\n",
        "![alt text](https://media.giphy.com/media/WVGSfyhUYBoiGLbZ7N/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGJHOZYOWZHR"
      },
      "source": [
        "## A bit of theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBd8PVGNWgfK"
      },
      "source": [
        "In this article I will tell you how to create a virtual character whose statements will be based on a transcript of my favorite animated science fiction sitcom. You can use characters and sitcoms of your choice. I added code to convert a regular text file with dialogs into a format that the model understands.\n",
        "\n",
        "As I already mentioned, [Transformers](https://huggingface.co/transformers/) library, which contains the latest NLP models (such as [BERT](https://huggingface.co/transformers/model_doc/bert.html), [XLNet](https://huggingface.co/transformers/model_doc/xlnet.html), [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html)) will help us in our task. You can read more about transformers in a beautifully illustrated [article](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar.\n",
        "\n",
        "![alt text](http://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png) Image from[ http://jalammar.github.io](http://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "Not so long ago, Microsoft’s [DialoGPT](https://huggingface.co/transformers/model_doc/dialogpt.html) was added to the Transformers model collection. DialoGPT is a GPT-2 model, trained on 147M multi-turn dialogue from Reddit discussion thread (you can learn more about GPT-2 [here](http://jalammar.github.io/illustrated-gpt2/)). This model is ideally suited for creating a virtual character for a fascinating conversation and even in the small implementation option it can maintain a coherent dialogue, which we will see now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hyTyW7Le2Sb"
      },
      "source": [
        "## First dialogue with DialoGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEqpXb4ofFGd"
      },
      "source": [
        "We will conduct all our experiments in Google Colab, its resources are enough to train the small DialoGPT model. Firstly, we will connect to Google Drive and install the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgL1yLLS09mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4837ba5-bb04-4eae-bc62-b441023123b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onU41i8g1J3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05552bf-6936-4872-99cf-0677f4919937"
      },
      "source": [
        "! pip -q install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Y1XcsqgXBQ"
      },
      "source": [
        "Let's move to the desired folder in which we will store all our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHNacD0k1HI3"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVSTlysV2jaM"
      },
      "source": [
        "Try to chat with DialoGPT without fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6qrl7_SvPKg",
        "outputId": "6e62b1c3-ae83-4444-dd96-5aa4102b168a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "0cb37b736de3441abeb40a16b7776021",
            "6d7c411037b64376982661ff15aa487b",
            "b1f26ed3384b4cfd95f61bc7626f9aff",
            "24025f5f822e4bd2805cd530da066dee",
            "e40ef8ee43594c6ba2289fe5a2f6c35f",
            "5c625e5deab5467d99f831e71115d03e",
            "95243484c30c4f00bbbca16aeb2fd358",
            "bbdfb9b142c24456a937d6c6a6549519",
            "50b696fad9ca41639c373a56dbe89420",
            "57582f68d3da440193c5231507aa5396",
            "f1b95b25bb904364abdbbab5946b81d1",
            "c79c82bccb85415ea8c90b86562ba663",
            "9cfd8ecf5ca741c8be36e3991769df7c",
            "b93ce7212179474bac487049babd6091",
            "c4de165618ff474b98e7807267bb3f10",
            "169f478857a34225b1db7098d1853326",
            "fdc2f1d145b14e008e2412b7c2270c6c",
            "03962a97d3e64bf9af87a2178ebf4e73",
            "ac87dfd2bb534a3c971b77360ac720ad",
            "8cb7b0940b8048409f906e2fcc45d07b",
            "e0f047765f4447478a96645ddef19ab7",
            "1d38c01aaf2d4f119be8bbe6406a5395",
            "eb47052903c64f3c8f3761b23ebe5685",
            "e7b7c7d62cfc4b609dbb3b364ab96187",
            "66dfb24424164c38b9ea9239c4c2dc40",
            "977924568223464ba8319deb85649633",
            "9132b14861004a11bb768d45ea490d45",
            "2f2610f8d9a943bd9e1e68111ae0d869",
            "6f0dd7a145d34376add89df435cbdb1e",
            "88a302de47b24ca98aa4427d7f9ab940",
            "aaa9eb2f876649df94df950b64697bda",
            "885fb41b92ca436aa6666dfe18ff92a0",
            "bda28c44f55b431ead843b1b249c363f",
            "aa20a48c6d724619bc1e960d0ebec5ae",
            "414a240375984693b83dd2f4f6125d01",
            "ed6231c81fa94be7988c5f7f41a2c8da",
            "8df2989bec5040488ad94d4a992e28fc",
            "3790f0538f694c638df1c5d548529124",
            "1e90ae173b6240a6919ff13461325aa1",
            "1366157f3dc44a47b58df8fb34bf7895",
            "e8c7a210fb844579aa605942d00ab4f3",
            "f7e0228d542d4087966470e6e5752d4a",
            "04d34430db16423b875734570ea10408",
            "c03b40558da3415cb6c55889efca0e35",
            "a7945faae5ea473a90041b3c0c814ffd",
            "f0669ef280ea4566b66bdcd5e73cc351",
            "59391bde7407468b961b221ee8e91e21",
            "65dd4fc5a31341118219da523987ddaa",
            "91aa32f87f0642bca448425f265db362",
            "690287478227420ca8dbc72a984145d2",
            "48c5232cb7264e4fa3239b00f288dbe3",
            "045522048ffc4c7ebabc0a699c4489f0",
            "9a4d35a836b24e05aa85b81faa4eec1e",
            "5054d181fb3c4cfa80e36c2db6f648d8",
            "dac550f8975841aba051d4a121252dcf",
            "7e91ad9eb7854d1e9d72ab588c434265",
            "2628cb319c794cefa5e5d09c969e9b17",
            "405f8a185c83430f9388d0e164c18f94",
            "5d4cd67ffb5d4617861704da9c9d5f7a",
            "cdbf1124dada4141b10cc8870b6bd6df",
            "766f9020eb8f46659794511d676ddddf",
            "4969da3253d24c179d0dd789bef571e4",
            "9471acceec1c4b8a80ee8ec29edba781",
            "bf364d97ca0a4933b277ace0cd4c3e37",
            "d6c6546ad07946469034ba8590e682b4",
            "2759f1a6be5444f9a7ff1b2f9f47fc84"
          ]
        }
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\",padding_side='left')\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cb37b736de3441abeb40a16b7776021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c79c82bccb85415ea8c90b86562ba663"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb47052903c64f3c8f3761b23ebe5685"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa20a48c6d724619bc1e960d0ebec5ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/auto/modeling_auto.py:1248: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/351M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7945faae5ea473a90041b3c0c814ffd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e91ad9eb7854d1e9d72ab588c434265"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjZaN5ilgd-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d9b254-b0fd-46f7-e532-66f92fa4aa21"
      },
      "source": [
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens    \n",
        "    chat_history_ids = model.generate(\n",
        "                      bot_input_ids, max_length=1000,\n",
        "                      pad_token_id=tokenizer.eos_token_id\n",
        "                      )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "    print(\"DialoGPT ORI: {}\".format(chat_history_ids[:, bot_input_ids.shape[-1]:][0]))    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> User:hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: Hi\n",
            "DialoGPT ORI: tensor([17250, 50256])\n",
            ">> User:how are you\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: How are you\n",
            "DialoGPT ORI: tensor([ 2437,   389,   345, 50256])\n",
            ">> User:can AI destory human\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: AI destory human\n",
            "DialoGPT ORI: tensor([20185,  2244,   652,  1692, 50256])\n",
            ">> User:really?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: AI destory human\n",
            "DialoGPT ORI: tensor([20185,  2244,   652,  1692, 50256])\n",
            ">> User:it's scary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DialoGPT: AI destory human\n",
            "DialoGPT ORI: tensor([20185,  2244,   652,  1692, 50256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbzm0BHOitsa"
      },
      "source": [
        "**User:**Hi Rick <br> \n",
        "**DialoGPT:** Hi Rick <br>\n",
        "**User:**How are you? <br>\n",
        "**DialoGPT:** I'm good, how are you? <br>\n",
        "**User:**I am fine. Where is Morty? <br>\n",
        "**DialoGPT:** He's in the basement. <br>\n",
        "**User:**Who is Morty? <br>\n",
        "**DialoGPT:** He's a Morty. <br>\n",
        "**User:**Who are you? <br>\n",
        "**DialoGPT:** I am a Morty. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAy2OBMW6QyD"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/L3WevKXIKFDaZBvV8Q/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "Not bad but not too impressive. We will fix it with fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuzSROqxjUKM"
      },
      "source": [
        "## Model initial configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC3qNlfp30aU"
      },
      "source": [
        "Let's train our own Rick chatbot. For start, we will need basic configuration and a dataset.\n",
        "Configuration and training scripts are mostly based on this [script](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) from Huggingface and great [tutorial](https://nathancooper.io/i-am-a-nerd/chatbot/deep-learning/gpt2/2020/05/12/chatbot-part-1.html) from Nathan Cooper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g91QzdqU2haO"
      },
      "source": [
        "\"\"\"\n",
        "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
        "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
        "using a masked language modeling (MLM) loss.\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utprDGf06OVt"
      },
      "source": [
        "# Args to allow for easy convertion of python script to notebook\n",
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = 'output-small'\n",
        "        self.model_type = 'gpt2'\n",
        "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        self.config_name = 'microsoft/DialoGPT-small'\n",
        "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "        self.cache_dir = 'cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qYqlTe9yx2"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo718Zb-961e"
      },
      "source": [
        "Our dialogues dataset will be based on a dataset used in Andrada Olteanu's [article](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts/) about Rick and Morty sentiment analysis. Big thanks to her work and also to Gabriel Hernandes, author of original [text dataset](https://github.com/ghhernandes/rickmorty-gan/tree/master/data)!\n",
        "\n",
        "![alt text](https://media.giphy.com/media/U6LOakQja88ImTnE6T/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "First of all we will use kaggle module to download needed dataset. You can read in more detail about module and how to get Kaggle API Token by this [link](https://github.com/Kaggle/kaggle-api). Or you can just download RickAndMortyScripts.csv file from [article](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts/) and place this file in your working directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbB-56mmm-rL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2bb9cc8-ec4e-4fde-9f31-6045b5330959"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "p0e9LhZI6KHu",
        "outputId": "a9b5cd76-030f-4769-c446-5afe16601e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b55ec167-904e-4a68-a97a-93d4167f028a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b55ec167-904e-4a68-a97a-93d4167f028a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"kangyinliang\",\"key\":\"36c8443a2786653618f754f7edb50e64\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "dvTvxYjM5_4M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HczUyTnyzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b82126e-34a0-4d85-a4e4-321bc5131fa5"
      },
      "source": [
        "!kaggle datasets download andradaolteanu/rickmorty-scripts -f RickAndMortyScripts.csv \n",
        "# !kaggle datasets download -d andradaolteanu/rickmorty-scripts"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RickAndMortyScripts.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivUgcYk5r_Ff"
      },
      "source": [
        "# !mv datasets%2F506221%2F935855%2FRickAndMortyScripts.csv RickAndMortyScripts.csv"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxHdyv67dptm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "5fa1ae27-9acd-4f26-853d-869371f96a87"
      },
      "source": [
        "# Let's look at original dataset\n",
        "all_rick = pd.read_csv('RickAndMortyScripts.csv')\n",
        "all_rick.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  season no.  episode no. episode name   name  \\\n",
              "0      0           1            1        Pilot   Rick   \n",
              "1      1           1            1        Pilot  Morty   \n",
              "2      2           1            1        Pilot   Rick   \n",
              "3      3           1            1        Pilot  Morty   \n",
              "4      4           1            1        Pilot   Rick   \n",
              "5      5           1            1        Pilot  Morty   \n",
              "6      6           1            1        Pilot   Rick   \n",
              "7      7           1            1        Pilot   Rick   \n",
              "8      8           1            1        Pilot  Morty   \n",
              "9      9           1            1        Pilot   Rick   \n",
              "\n",
              "                                                line  \n",
              "0  Morty! You gotta come on. Jus'... you gotta co...  \n",
              "1                       What, Rick? What’s going on?  \n",
              "2                   I got a surprise for you, Morty.  \n",
              "3  It's the middle of the night. What are you tal...  \n",
              "4  Come on, I got a surprise for you.  Come on, h...  \n",
              "5                Ow! Ow! You're tugging me too hard!  \n",
              "6  We gotta go, gotta get outta here, come on. Go...  \n",
              "7  What do you think of this... flying vehicle, M...  \n",
              "8  Yeah, Rick... I-it's great. Is this the surprise?  \n",
              "9  Morty. I had to... I had to do it. I had— I ha...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24790816-3b9f-4755-bb05-2b284d3e1c40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>season no.</th>\n",
              "      <th>episode no.</th>\n",
              "      <th>episode name</th>\n",
              "      <th>name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Morty! You gotta come on. Jus'... you gotta co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24790816-3b9f-4755-bb05-2b284d3e1c40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24790816-3b9f-4755-bb05-2b284d3e1c40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24790816-3b9f-4755-bb05-2b284d3e1c40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51hsl2mAG8v"
      },
      "source": [
        "We will convert this dataset in a way that every responce row will contain **n** previous responces as a context. For our purposes seven previous responces will be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyL7Dx1bbLRC"
      },
      "source": [
        "contexted = []\n",
        "\n",
        "n = 7\n",
        "\n",
        "for i in range(n, len(all_rick['line'])):\n",
        "  row = []\n",
        "  prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n",
        "  for j in range(i, prev, -1):\n",
        "    row.append(all_rick['line'][j])\n",
        "  contexted.append(row)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_cwbBolVi14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36693d01-9861-42b6-f9fb-a0519f67eef6"
      },
      "source": [
        "len(contexted)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNkYLty-VhTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b5ec84-d13e-4979-eac3-7237125107ff"
      },
      "source": [
        "columns = ['response', 'context'] \n",
        "columns = columns + ['context/'+str(i) for i in range(n-1)]\n",
        "columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['response',\n",
              " 'context',\n",
              " 'context/0',\n",
              " 'context/1',\n",
              " 'context/2',\n",
              " 'context/3',\n",
              " 'context/4',\n",
              " 'context/5']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPafxqIYgurW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "10f1feac-9bb4-4b86-9932-9bc728a16105"
      },
      "source": [
        "df = pd.DataFrame.from_records(contexted, columns=columns)\n",
        "df.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            response  \\\n",
              "0  What do you think of this... flying vehicle, M...   \n",
              "1  Yeah, Rick... I-it's great. Is this the surprise?   \n",
              "2  Morty. I had to... I had to do it. I had— I ha...   \n",
              "3                                    What?! A bomb?!   \n",
              "4  We're gonna drop it down there just get a whol...   \n",
              "\n",
              "                                             context  \\\n",
              "0  We gotta go, gotta get outta here, come on. Go...   \n",
              "1  What do you think of this... flying vehicle, M...   \n",
              "2  Yeah, Rick... I-it's great. Is this the surprise?   \n",
              "3  Morty. I had to... I had to do it. I had— I ha...   \n",
              "4                                    What?! A bomb?!   \n",
              "\n",
              "                                           context/0  \\\n",
              "0                Ow! Ow! You're tugging me too hard!   \n",
              "1  We gotta go, gotta get outta here, come on. Go...   \n",
              "2  What do you think of this... flying vehicle, M...   \n",
              "3  Yeah, Rick... I-it's great. Is this the surprise?   \n",
              "4  Morty. I had to... I had to do it. I had— I ha...   \n",
              "\n",
              "                                           context/1  \\\n",
              "0  Come on, I got a surprise for you.  Come on, h...   \n",
              "1                Ow! Ow! You're tugging me too hard!   \n",
              "2  We gotta go, gotta get outta here, come on. Go...   \n",
              "3  What do you think of this... flying vehicle, M...   \n",
              "4  Yeah, Rick... I-it's great. Is this the surprise?   \n",
              "\n",
              "                                           context/2  \\\n",
              "0  It's the middle of the night. What are you tal...   \n",
              "1  Come on, I got a surprise for you.  Come on, h...   \n",
              "2                Ow! Ow! You're tugging me too hard!   \n",
              "3  We gotta go, gotta get outta here, come on. Go...   \n",
              "4  What do you think of this... flying vehicle, M...   \n",
              "\n",
              "                                           context/3  \\\n",
              "0                   I got a surprise for you, Morty.   \n",
              "1  It's the middle of the night. What are you tal...   \n",
              "2  Come on, I got a surprise for you.  Come on, h...   \n",
              "3                Ow! Ow! You're tugging me too hard!   \n",
              "4  We gotta go, gotta get outta here, come on. Go...   \n",
              "\n",
              "                                           context/4  \\\n",
              "0                       What, Rick? What’s going on?   \n",
              "1                   I got a surprise for you, Morty.   \n",
              "2  It's the middle of the night. What are you tal...   \n",
              "3  Come on, I got a surprise for you.  Come on, h...   \n",
              "4                Ow! Ow! You're tugging me too hard!   \n",
              "\n",
              "                                           context/5  \n",
              "0  Morty! You gotta come on. Jus'... you gotta co...  \n",
              "1                       What, Rick? What’s going on?  \n",
              "2                   I got a surprise for you, Morty.  \n",
              "3  It's the middle of the night. What are you tal...  \n",
              "4  Come on, I got a surprise for you.  Come on, h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-518faf20-fee3-4545-9b29-6516e9518f59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>context/0</th>\n",
              "      <th>context/1</th>\n",
              "      <th>context/2</th>\n",
              "      <th>context/3</th>\n",
              "      <th>context/4</th>\n",
              "      <th>context/5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "      <td>Morty! You gotta come on. Jus'... you gotta co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What?! A bomb?!</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We're gonna drop it down there just get a whol...</td>\n",
              "      <td>What?! A bomb?!</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-518faf20-fee3-4545-9b29-6516e9518f59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-518faf20-fee3-4545-9b29-6516e9518f59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-518faf20-fee3-4545-9b29-6516e9518f59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeM8pvEjigq"
      },
      "source": [
        "Split our dataset into a training and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CeutVVlL85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "84121f19-6a5e-42f4-e50d-f05e726d5db3"
      },
      "source": [
        "trn_df, val_df = train_test_split(df, test_size = 0.1)\n",
        "trn_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               response  \\\n",
              "623                                        Ow, ow ouch!   \n",
              "1671                       Oof! Didn't see that comin'.   \n",
              "1852  Wh-why would you say something like that, Big ...   \n",
              "398   You're putting too much pressure on yourself, ...   \n",
              "1320  Nobody needs anything! Okay, it's fine. I mean...   \n",
              "\n",
              "                                                context  \\\n",
              "623                 Huh, what do you know, it's working   \n",
              "1671                                              STOP!   \n",
              "1852  Don't worry about Rick, Big Morty. He's new. H...   \n",
              "398   Yeah, this is a bunch of bullcrap. Who cares w...   \n",
              "1320  Great question, Summer. The unfortunate answer...   \n",
              "\n",
              "                                              context/0  \\\n",
              "623   Whatever you're asking, the answer is I'm amaz...   \n",
              "1671                   ALL ABOOOOOOARD, MOTHERFUCKER!!!   \n",
              "1852  M-m-my partner. Morty, you're right. Mortytown...   \n",
              "398                             Oh, uh, um ... \"Bitch.\"   \n",
              "1320    Can't you just turn yourself back into a human?   \n",
              "\n",
              "                                              context/1  \\\n",
              "623   Alright, since this time crystal exists in bot...   \n",
              "1671                          One million times better!   \n",
              "1852                                           Morty...   \n",
              "398   Oh, no! I'm late to class, bitch! Oh, no! I'm ...   \n",
              "1320  It's okay, Beth. I understand Morty's suspicio...   \n",
              "\n",
              "                                              context/2  \\\n",
              "623                                          We “isn't”   \n",
              "1671                                              Yeah?   \n",
              "1852  Big Morty likes to contribute to keeping the p...   \n",
              "398   Oh, boy, Rick. I can only imagine what horribl...   \n",
              "1320                                             Morty!   \n",
              "\n",
              "                                              context/3  \\\n",
              "623                                                 Or?   \n",
              "1671  I conceived a child with Million Ants and it d...   \n",
              "1852  They had a little accident. They won't be caus...   \n",
              "398        Looks like scary Terry's having a nightmare.   \n",
              "1320  Rick, did you do this on purpose to get out of...   \n",
              "\n",
              "                                              context/4  \\\n",
              "623                                               Or...   \n",
              "1671                                             WHAT?!   \n",
              "1852  \"The Creepy Morty\". What is it your kind's alw...   \n",
              "398   Morty, this is perfect. After a little scary c...   \n",
              "1320  Oh, my God. Beth, oh, it totally slipped my mi...   \n",
              "\n",
              "                                              context/5  \n",
              "623   Look, there's no time to hold me accountable, ...  \n",
              "1671  You wish this was about sex! We loved each oth...  \n",
              "1852                                 What is the place?  \n",
              "398   Yeah, I know, I know. I shouldn't take my ange...  \n",
              "1320  We have an appointment downtown that was set a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ab7526c-a11f-4c73-8f15-2c37e6645520\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>context/0</th>\n",
              "      <th>context/1</th>\n",
              "      <th>context/2</th>\n",
              "      <th>context/3</th>\n",
              "      <th>context/4</th>\n",
              "      <th>context/5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>Ow, ow ouch!</td>\n",
              "      <td>Huh, what do you know, it's working</td>\n",
              "      <td>Whatever you're asking, the answer is I'm amaz...</td>\n",
              "      <td>Alright, since this time crystal exists in bot...</td>\n",
              "      <td>We “isn't”</td>\n",
              "      <td>Or?</td>\n",
              "      <td>Or...</td>\n",
              "      <td>Look, there's no time to hold me accountable, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1671</th>\n",
              "      <td>Oof! Didn't see that comin'.</td>\n",
              "      <td>STOP!</td>\n",
              "      <td>ALL ABOOOOOOARD, MOTHERFUCKER!!!</td>\n",
              "      <td>One million times better!</td>\n",
              "      <td>Yeah?</td>\n",
              "      <td>I conceived a child with Million Ants and it d...</td>\n",
              "      <td>WHAT?!</td>\n",
              "      <td>You wish this was about sex! We loved each oth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1852</th>\n",
              "      <td>Wh-why would you say something like that, Big ...</td>\n",
              "      <td>Don't worry about Rick, Big Morty. He's new. H...</td>\n",
              "      <td>M-m-my partner. Morty, you're right. Mortytown...</td>\n",
              "      <td>Morty...</td>\n",
              "      <td>Big Morty likes to contribute to keeping the p...</td>\n",
              "      <td>They had a little accident. They won't be caus...</td>\n",
              "      <td>\"The Creepy Morty\". What is it your kind's alw...</td>\n",
              "      <td>What is the place?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>You're putting too much pressure on yourself, ...</td>\n",
              "      <td>Yeah, this is a bunch of bullcrap. Who cares w...</td>\n",
              "      <td>Oh, uh, um ... \"Bitch.\"</td>\n",
              "      <td>Oh, no! I'm late to class, bitch! Oh, no! I'm ...</td>\n",
              "      <td>Oh, boy, Rick. I can only imagine what horribl...</td>\n",
              "      <td>Looks like scary Terry's having a nightmare.</td>\n",
              "      <td>Morty, this is perfect. After a little scary c...</td>\n",
              "      <td>Yeah, I know, I know. I shouldn't take my ange...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1320</th>\n",
              "      <td>Nobody needs anything! Okay, it's fine. I mean...</td>\n",
              "      <td>Great question, Summer. The unfortunate answer...</td>\n",
              "      <td>Can't you just turn yourself back into a human?</td>\n",
              "      <td>It's okay, Beth. I understand Morty's suspicio...</td>\n",
              "      <td>Morty!</td>\n",
              "      <td>Rick, did you do this on purpose to get out of...</td>\n",
              "      <td>Oh, my God. Beth, oh, it totally slipped my mi...</td>\n",
              "      <td>We have an appointment downtown that was set a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ab7526c-a11f-4c73-8f15-2c37e6645520')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ab7526c-a11f-4c73-8f15-2c37e6645520 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ab7526c-a11f-4c73-8f15-2c37e6645520');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86F3WhnFO4H8"
      },
      "source": [
        "Now will convert our dataset in a format suitable for our model. Basically we will concatenate responses in one string for each row (additionally we will add special 'end of string' token between responses, so the model will understand end of each response in a string).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX7jeWpYmOe_"
      },
      "source": [
        "def construct_conv(row, tokenizer, eos = True):\n",
        "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))  #? why reverse\n",
        "    conv = flatten(conv)\n",
        "    return conv\n",
        "\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
        "\n",
        "        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n",
        "\n",
        "        directory = args.cache_dir\n",
        "        cached_features_file = os.path.join(\n",
        "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
        "        )\n",
        "\n",
        "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
        "\n",
        "            self.examples = []\n",
        "            for _, row in df.iterrows():\n",
        "                conv = construct_conv(row, tokenizer)\n",
        "                self.examples.append(conv)\n",
        "\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item], dtype=torch.long)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = ConversationDataset(PreTrainedTokenizer, args,trn_df)"
      ],
      "metadata": {
        "id": "IPJiXFvRuuqK",
        "outputId": "7b045515-3d6a-47f3-eab0-385713a1b2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7baf06797d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConversationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-a0c8626d0dba>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, args, df, block_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mblock_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len_single_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'PreTrainedTokenizer' has no attribute 'max_len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naaRHoXgnStq"
      },
      "source": [
        "# Cacheing and storing of data/checkpoints\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
        "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
        "    ordering_and_checkpoint_path = []\n",
        "\n",
        "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
        "\n",
        "    for path in glob_checkpoints:\n",
        "        if use_mtime:\n",
        "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
        "        else:\n",
        "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
        "            if regex_match and regex_match.groups():\n",
        "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
        "\n",
        "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
        "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
        "    return checkpoints_sorted\n",
        "\n",
        "\n",
        "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
        "    if not args.save_total_limit:\n",
        "        return\n",
        "    if args.save_total_limit <= 0:\n",
        "        return\n",
        "\n",
        "    # Check if we should delete older checkpoint(s)\n",
        "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
        "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
        "        return\n",
        "\n",
        "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
        "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
        "    for checkpoint in checkpoints_to_be_deleted:\n",
        "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
        "        shutil.rmtree(checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkvMNnrnVHQw"
      },
      "source": [
        "## Training and Evaluating\n",
        "\n",
        "There will be quite a lot of code needed for training our model but don’t worry, everything should work as is, the main thing is to give the model the dataset in the right format.\n",
        "\n",
        "![alt text](https://media.giphy.com/media/KetvQljQJdEMscR83K/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXzKlXHeu0Mb"
      },
      "source": [
        "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    # add_special_tokens_(model, tokenizer)\n",
        "\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if (\n",
        "        args.model_name_or_path\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproducibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            inputs, labels = (batch, batch)\n",
        "            if inputs.shape[1] > 1024: continue\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "            model.train()\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    checkpoint_prefix = \"checkpoint\"\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
        "                    os.makedirs(output_dir, exist_ok=True)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "# Evaluation of some model\n",
        "\n",
        "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
        "    os.makedirs(eval_output_dir, exist_ok=True)\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    model.eval()\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        inputs, labels = (batch, batch)\n",
        "        inputs = inputs.to(args.device)\n",
        "        labels = labels.to(args.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            lm_loss = outputs[0]\n",
        "            eval_loss += lm_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
        "\n",
        "    result = {\"perplexity\": perplexity}\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MGD6bFXV4Z-"
      },
      "source": [
        "# Main runner\n",
        "\n",
        "def main(df_trn, df_val):\n",
        "    args = Args()\n",
        "    \n",
        "    if args.should_continue:\n",
        "        sorted_checkpoints = _sorted_checkpoints(args)\n",
        "        if len(sorted_checkpoints) == 0:\n",
        "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
        "        else:\n",
        "            args.model_name_or_path = sorted_checkpoints[-1]\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "        and not args.should_continue\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    device = torch.device(\"cuda\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
        "    model = AutoModelWithLMHead.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=False,\n",
        "        config=config,\n",
        "        cache_dir=args.cache_dir,\n",
        "    )\n",
        "    model.to(args.device)\n",
        "    \n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
        "\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
        "    if args.do_train:\n",
        "        # Create output directory if needed\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEHDzR0Vjs7"
      },
      "source": [
        "It is time to train our model!\n",
        "\n",
        "![alt text](https://media.giphy.com/media/Tia3dkakIp2m4uGoDI/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__iqR8YFV-Ex"
      },
      "source": [
        "main(trn_df, val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eDkPEuvbD47"
      },
      "source": [
        "## Chatting with  Rick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVqotI05gOS"
      },
      "source": [
        "The model is ready, so it's time to chat with Rick. But don't forget that Rick can be rude, I warned you.\n",
        "\n",
        "A variety of methods can be used in responces generation. You can find more details about these methods by this [link](https://huggingface.co/blog/how-to-generate). \n",
        "\n",
        "![alt text](https://media.giphy.com/media/ftl8NiWz2C3tuXOn3w/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeqMwZktv7N"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "model = AutoModelWithLMHead.from_pretrained('output-small')\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    # print(new_user_input_ids)\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=100, \n",
        "        top_p=0.7,\n",
        "        temperature = 0.8\n",
        "    )\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"RickBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zq2wJFtss1e"
      },
      "source": [
        "**User**:How are you, Rick? <br>\n",
        "**RickBot**: I'm fine. <br>\n",
        "**User**:Where is Morty? <br>\n",
        "**RickBot**: He's in a hospital. <br>\n",
        "**User**:Why? <br>\n",
        "**RickBot**: Well, that depends on who breaks first -- me or the hospital. I mean, you know, the one that keeps giving me pills. <br>\n",
        "**User**:I don't understand <br>\n",
        "**RickBot**: Whoa! Whoa! <br>\n",
        "**User**:I see, you took your pills <br>\n",
        "**RickBot**: Hey, I-I'm not proud of this. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvxnAOkTBTIJ"
      },
      "source": [
        "I will give an example of a few more dialogues to show how Ricky is our Rick now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gX23iKkd0g"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/eNpXWzGIMRjIo4lXT8/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "**User**:Who are you? <br>\n",
        "**RickBot**: A musician, I'm not a musician, but I'm pretty close to you. <br>\n",
        "**User**:What kind of musician are you? <br>\n",
        "**RickBot**: Who cares? I'm a musician. <br>\n",
        "**User**:Ok, play a song for me <br>\n",
        "**RickBot**: Shut up and listen to me, Morty. Listen to me. Listen! I'm the leader of a bunch of different death worlds, and I'm just trying to assemble a band. I'm gonna make this one-piece, and you're gonna be part of it. <br>\n",
        "**User**:ok <br>\n",
        "**RickBot**: Whoa, whoa, hey, who's this? <br>\n",
        "**User**:This is Morty <br>\n",
        "**RickBot**: Geez!!! <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDiz2J0LBqaq"
      },
      "source": [
        "![alt text](https://i.kym-cdn.com/news/posts/desktop/000/000/247/Screenshot_21.jpg)\n",
        "\n",
        "Image from [news.knowyourmeme.com](https://news.knowyourmeme.com/news/elon-musks-rick-and-morty-cameo-is-a-meme-reference)\n",
        "\n",
        "**User**:What do you think about Elon Musk? <br>\n",
        "**RickBot**: I think about him a lot. <br>\n",
        "**User**:But what exactly do you think? <br>\n",
        "**RickBot**: He's not a bad guy. He's just... not a very charismatic one. <br>\n",
        "**User**:I think he is charismatic <br>\n",
        "**RickBot**: He is. <br>\n",
        "**User**:What else you can say about him? <br>\n",
        "**RickBot**: You don't have to say anything. He is the leader of your class. <br>\n",
        "**User**:ok, thank you <br>\n",
        "**RickBot**: !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezq6Qtl_3NtD"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/YSTmV6MWEkgW0HblZQ/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "**User**:hey, go get me a burger <br>\n",
        "RickBot: Whoa, whoa, hold on a second, let's not get crazy. This is gonna be good. <br>\n",
        "**User**:I'm hungry! c'mon, buy me a burger or better two <br>\n",
        "**RickBot**: Holy crap. <br>\n",
        "**User**:no crappy burger, a good one! <br>\n",
        "**RickBot**: What the hell? <br>\n",
        "**User**:don't be so bad, feed me <br>\n",
        "**RickBot**: I'll be back as fast as I can, Morty. <br>\n",
        "**User**:good boy, and don't forget ketchup and fries <br>\n",
        "**RickBot**: !!!!!! <br>\n",
        "**User**:what a hell? can you reply with words? <br>\n",
        "**RickBot**: Yes!! I will!! We will go out on a date. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Woi683Eyvttc"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZmkXDkv4BAl"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/YQBWwGLJtFDQIATck5/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "Congratulations! Our virtual Rick is alive (almost)! With the help of fine-tuning our model on a small dataset, we were able to create a virtual character with whom we can conduct interesting dialogs. \n",
        "\n",
        "Using the proposed approach you can create many interesting virtual characters based on an arbitrary dialogs dataset (just a csv file with replicas, one replica per line)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jAMH0XPuE-f"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjd1pCZxukWh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofg7iJNFyjBs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
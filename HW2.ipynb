{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODgN5PLsnVTqRzgTCF9kh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heimmer/NLP/blob/main/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quention 1  "
      ],
      "metadata": {
        "id": "KWv9B3S3KISK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1\n",
        "**answer**  \n",
        "- **vanishing/exploding gradient**:   \n",
        "Loss function of RNN is defined as sum of the loss at every time step. After decomposing the loss at each time step according to the chain rule, $\\frac{∂h_t}{∂h1}$ is the only term which is hard to compute, we need to further decompose it to $\\frac{∂h_t}{∂h_{t-1}}\\frac{∂h_{t-1}}{∂h_{t-2}}...\\frac{∂h2}{∂h1}$. It's fine that each $\\frac{∂h_t}{∂h_{t-1}}$ is a bit larger or smaller than 1, but in RNN, the time step T can be large. After a expotential calculation of power T, the gradient can be very large or small, which is the so-called vanishing/exploding gradient problem.  \n",
        "- **long-term dependency**  \n",
        "Human language system is complicated, sometimes information related to the t-th word appeared very early in the sentence. If the gradient is small, the model can't learn this dependency, which is so-called long-term dependency problem."
      ],
      "metadata": {
        "id": "sz1opys1KOXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2  \n",
        "**answer**  \n",
        "Yes, LSTM can solve the problems of vanishing and exploding gradient.  \n",
        "The recursive derivative in Vanilla RNN is the main reason of vanishing/exploding gradient.But LSTM introduces a set of gating units and a cell state to control the memory intead of adding up all history.  \n",
        "- **forget gate** controls what is kept vs forgotten from previous cell state  \n",
        "- **input gate** controls what part of new cell content are written to the cell\n",
        "- **output gate** controls what parts of cell are output to hidden state  \n",
        "\n",
        "Those gates can help to adjust and prevent the gradients from vanishing/exploding"
      ],
      "metadata": {
        "id": "geAO_v1pXG1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3  \n",
        "**answer** \n",
        "$4*[(d_i+d_o)*d_o+d_o]$  \n",
        "- in each LSTM cell, there are 4 non-linear transformations (3 gates and 1 tanh)\n",
        "- dim of input is $d_i$, dim of hidden state from previous LSTM cell is $d_o$\n",
        "- at first, we need to combine them together, so dim of the combination is $d_i+d_o$  \n",
        "- output of each non-linear transformation $σ$ is of dim $d_o$, and dim of bias is also $d_o$\n",
        "- so number of parameters of each non-linear transformation is $(d_i+d_o)*d_o+d_o$\n",
        "- 4 non-linear transformations are different, they don't share parameters, so number of parameters of the whole cell is $4*[(d_i+d_o)*d_o+d_o]$"
      ],
      "metadata": {
        "id": "-si8IvKbmfSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4  \n",
        "**answer** : 12585  \n",
        "- vocab_size=1000, embedding_dim=10, so number of parameters in embedding matrix is 1000*10=10000\n",
        "- embedding_dim=10, so input_size of LSTM cell is 10; hidden_size=20, according to last question, number of parameters in LSTM cell is 4*[(10+20)*20+20]=2480\n",
        "- hidden_size=20, num_class=5, so number of parameters in decoder is 20*5+5=105\n",
        "- total number of parameters is 10000+2480+105 = 12585"
      ],
      "metadata": {
        "id": "0fF1_BBWxibf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MA7D8hcyIs8W"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self, vocab_size=1000, embedding_dim=10,\n",
        "        hidden_size=20, num_class=5):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size,\n",
        "    bidirectional=True, num_layers=1)\n",
        "    self.decoder = nn.Linear(hidden_size, num_class, bias=True)\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "id": "hHR1mwi2xnOK",
        "outputId": "37f4168a-2271-4b1c-e9d9-3a1f700b6c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f7d03300ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.named_parameters():\n",
        "    print(param[0])"
      ],
      "metadata": {
        "id": "vgxjg0tQzY8M",
        "outputId": "4067d43f-04dd-442a-d801-698c06eac668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.weight\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "decoder.weight\n",
            "decoder.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  print(param.shape)"
      ],
      "metadata": {
        "id": "mHYZG1XkxpAA",
        "outputId": "8cfae095-c287-453c-d6c1-d57a6fbf3d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 10])\n",
            "torch.Size([80, 10])\n",
            "torch.Size([80, 20])\n",
            "torch.Size([80])\n",
            "torch.Size([80])\n",
            "torch.Size([80, 10])\n",
            "torch.Size([80, 20])\n",
            "torch.Size([80])\n",
            "torch.Size([80])\n",
            "torch.Size([5, 20])\n",
            "torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config(dd)"
      ],
      "metadata": {
        "id": "vXPJ1zyXyDWm",
        "outputId": "8390bac9-5156-4915-d1bf-2f1291c55c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bf5a57509985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MyModel' object has no attribute 'config'"
          ]
        }
      ]
    }
  ]
}